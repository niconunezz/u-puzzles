{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161a016-8d1c-468c-84ea-4ab57ccdca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
    "!pip install --no-deps cut_cross_entropy unsloth_zoo\n",
    "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "!pip install --no-deps unsloth\n",
    "!pip install transformers tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f51e5-1fe9-430a-8d10-5bff70fe5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions used through the entire notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import set_seed\n",
    "import time\n",
    "import inspect\n",
    "import os\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "HAS_BFLOAT16 = (major_version >= 8)\n",
    "from inspect import currentframe as _C, getframeinfo\n",
    "_F = lambda c: getframeinfo(c).lineno # Gets line number\n",
    "WARN = lambda x: print(f\"\\033[31m{x}\\033[0m\") # Red colored warnings\n",
    "\n",
    "# https://stackoverflow.com/questions/18425225/getting-the-name-of-a-variable-as-a-string\n",
    "def NAME(var):\n",
    "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
    "    names = [var_name for var_name, var_val in callers_local_vars if var_val is var]\n",
    "    return names[0] if len(names) != 0 else \"\"\n",
    "\n",
    "def assert_same(x, y, line, dtype):\n",
    "    assert(x.dtype == dtype)\n",
    "    try: torch.testing.assert_close(x, y, check_stride = True, atol=1e-1, rtol=1e-1)\n",
    "    except Exception as error:\n",
    "        raise RuntimeError(\n",
    "            f\"Failed allclose at line [{line}]: {NAME(x)}, {NAME(y)}\\n{str(error)}\"\n",
    "        )\n",
    "\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357bf28-e502-49b8-a6db-10564469c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitsandbytes.nn import Linear4bit\n",
    "from transformers.activations import ACT2FN\n",
    "from unsloth.kernels.utils import fast_dequantize\n",
    "from peft.utils.integrations import dequantize_module_weight as peft_dequantize\n",
    "def unsloth_dequantize(weight):\n",
    "    return fast_dequantize(weight.weight, weight.weight.quant_state)\n",
    "\n",
    "def bnb_Linear4bit(hd, m, dtype = torch.float16):\n",
    "    return Linear4bit(\n",
    "        hd, m, bias = None,\n",
    "        compute_dtype       = dtype,\n",
    "        compress_statistics = True,\n",
    "        quant_type          = \"nf4\",\n",
    "    )\n",
    "\n",
    "# [NEW] as at 18th Feb 2025\n",
    "def assert_correct_bnb(weight, dtype):\n",
    "    assert(weight.weight.dtype == torch.uint8)\n",
    "    assert(weight.weight.quant_state.dtype == dtype)\n",
    "    assert(weight.weight.quant_state.absmax.dtype == torch.uint8)\n",
    "    assert(weight.weight.quant_state.code.dtype == torch.float32)\n",
    "    assert(weight.weight.quant_state.offset.dtype == torch.float32)\n",
    "    assert(weight.weight.quant_state.blocksize == 64)\n",
    "    assert(weight.weight.quant_state.state2.absmax.dtype == torch.float32)\n",
    "    assert(weight.weight.quant_state.state2.code.dtype == torch.float32)\n",
    "    assert(weight.weight.quant_state.state2.blocksize == 256)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hd = 4096, m = 14336, dtype = torch.float16):\n",
    "        super().__init__()\n",
    "        self.gate_proj = bnb_Linear4bit(hd, m, dtype = dtype).to(\"cuda\")\n",
    "        self.up_proj   = bnb_Linear4bit(hd, m, dtype = dtype).to(\"cuda\")\n",
    "        self.down_proj = bnb_Linear4bit(m, hd, dtype = dtype).to(\"cuda\")\n",
    "        # [NEW] as at 18th Feb 2025\n",
    "        self.gate_proj.weight.quant_state.dtype = dtype\n",
    "        self.up_proj  .weight.quant_state.dtype = dtype\n",
    "        self.down_proj.weight.quant_state.dtype = dtype\n",
    "        self.act_fn = ACT2FN[\"silu\"]\n",
    "    def forward(self, x):\n",
    "        return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
    "\n",
    "def mlp_forward(X, mlp, fx):\n",
    "    up   = X @ fx(mlp.  up_proj).t()\n",
    "    gate = X @ fx(mlp.gate_proj).t()\n",
    "    h = mlp.act_fn(gate) * up\n",
    "    down = h @ fx(mlp.down_proj).t()\n",
    "    return down\n",
    "\n",
    "def mlp_dequantize(X, mlp, fx):\n",
    "    a = fx(mlp.  up_proj).t(); torch.cuda.synchronize()\n",
    "    b = fx(mlp.gate_proj).t(); torch.cuda.synchronize()\n",
    "    c = fx(mlp.down_proj).t(); torch.cuda.synchronize()\n",
    "    return a, b, c\n",
    "\n",
    "def test_dequantize(dequantize_fx):\n",
    "    elapsed = 0\n",
    "    options = [\n",
    "        (2, 3333, 2048,  8192, 3407, torch.float16),\n",
    "        (5,  777, 1024,  4096, 3409, torch.bfloat16),\n",
    "        (3, 2048, 4096, 14336, 3408, torch.bfloat16),\n",
    "    ]\n",
    "    for (bsz, qlen, hd, m, seed, dt) in options:\n",
    "        set_seed(seed)\n",
    "        torch.set_default_dtype(torch.float32)\n",
    "        mlp = MLP(hd = hd, m = m, dtype = dt)\n",
    "        X = torch.randn((bsz, qlen, hd), device = \"cuda\", dtype = dt)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # Warmup\n",
    "        for _ in range(2):\n",
    "            assert_same( mlp_forward(X, mlp, dequantize_fx), mlp(X), _F(_C()), dt)\n",
    "            # [NEW] as at 18th Feb 2025\n",
    "            assert_correct_bnb(mlp.  up_proj, dt)\n",
    "            assert_correct_bnb(mlp.gate_proj, dt)\n",
    "            assert_correct_bnb(mlp.down_proj, dt)\n",
    "            a, b, c = mlp_dequantize(X, mlp, dequantize_fx)\n",
    "            A, B, C = mlp_dequantize(X, mlp, unsloth_dequantize)\n",
    "            assert_same(a, A, _F(_C()), dt)\n",
    "            assert_same(b, B, _F(_C()), dt)\n",
    "            assert_same(c, C, _F(_C()), dt)\n",
    "\n",
    "        # Benchmarking\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        for _ in range(1000): mlp_dequantize(X, mlp, dequantize_fx)\n",
    "        elapsed += time.time() - start\n",
    "    return elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4656412-4dde-45a0-b73c-e15407a3f161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5299334526062012"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth.kernels.utils import fast_dequantize\n",
    "def unsloth_dequantize(weight):\n",
    "    return fast_dequantize(weight.weight, weight.weight.quant_state)\n",
    "test_dequantize(unsloth_dequantize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f657f7-2c56-4ea5-9073-765a71b747f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.76436448097229"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft.utils.integrations import dequantize_module_weight as peft_dequantize\n",
    "test_dequantize(peft_dequantize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8350d-9656-4fab-8c56-291dfdeb50c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from triton import jit\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "def _your_dequantize_nf4_kernel(w_ptr, w_out, abs_ptrs,\n",
    "                                offset_ptr, \n",
    "                                abs2_ptrs, code2,\n",
    "                                block_size2,gsize,code,blocks:tl.constexpr, Br:tl.constexpr):\n",
    "    \n",
    "\n",
    "    pid = tl.program_id(0)\n",
    "    \n",
    "    if pid < gsize:\n",
    "\n",
    "        absmax_group = pid*blocks + tl.arange(0,blocks) # can be coalesced\n",
    "        absmax = (tl.load(abs_ptrs + absmax_group,  eviction_policy= \"evict_first\"))\n",
    "\n",
    "        lz = tl.inline_asm_elementwise(\n",
    "        # efficient log2(blockwise2)\n",
    "        asm=\"\"\"\n",
    "        {\n",
    "            clz.b32 $0, $1;\n",
    "        }\n",
    "        \"\"\",\n",
    "        constraints=(\n",
    "            \"=r,r\"),\n",
    "        args=[block_size2],\n",
    "        dtype=(tl.int32),\n",
    "        is_pure=True,\n",
    "        pack=1,\n",
    "        )\n",
    "\n",
    "        absmax_group2 = (absmax_group)>>(31-lz)\n",
    "        real_absmax = tl.load(code2 + absmax,  eviction_policy= \"evict_last\")\n",
    "        absmax2 = tl.load(abs2_ptrs + absmax_group2,  eviction_policy= \"evict_last\")\n",
    "        offset = tl.load(offset_ptr,  eviction_policy= \"evict_last\") \n",
    "        final_absmax = absmax2 * real_absmax + offset\n",
    "\n",
    "        w_off = pid*(Br//2) + tl.arange(0, blocks)[:, None]*(Br//(2*blocks)) + tl.arange(0, Br//(2*blocks))[None, :]\n",
    "\n",
    "        w_packed = tl.load(w_ptr + w_off,  eviction_policy= \"evict_first\")\n",
    "        w_packed2 = tl.interleave(w_packed,w_packed)\n",
    "        \n",
    "\n",
    "        shift_sh = tl.arange(0, blocks)[:, None]*(Br//(blocks)) + tl.arange(0, Br//(blocks))[None, :]\n",
    "        shift = tl.where(shift_sh % 2 == 0, 4, 0)\n",
    "\n",
    "        shifted_w = (w_packed2 >> shift) & 0xF\n",
    "        \n",
    "        real_w = tl.load(shifted_w + code, eviction_policy= \"evict_last\")\n",
    "\n",
    "        scaled_w = (real_w* final_absmax[:, None])\n",
    "\n",
    "        out_off = pid*Br + tl.arange(0, blocks)[:, None]*(Br//blocks) + tl.arange(0, Br//blocks)[None, :]\n",
    "        \n",
    "        tl.store(w_out + out_off, scaled_w, eviction_policy= \"evict_first\")\n",
    "    return\n",
    "\n",
    "def _your_dequantize_nf4(weight, quant_state):\n",
    "    device = 'cuda:0'\n",
    "    out_dtype = quant_state.dtype\n",
    "    code = quant_state.code\n",
    "\n",
    "    absmax = quant_state.absmax #uint8\n",
    "    real_shape = quant_state.shape\n",
    "    block_size = quant_state.blocksize\n",
    "\n",
    "    absmax2 = quant_state.state2.absmax #f32\n",
    "    code2 = quant_state.state2.code #f32\n",
    "    block_size2 = quant_state.state2.blocksize\n",
    "\n",
    "    size = weight.shape[0]\n",
    "    offset = quant_state.offset\n",
    "    out_size = size*2\n",
    "\n",
    "    Br = 8192\n",
    "    blocks = Br//block_size\n",
    "    \n",
    "    gsize = (triton.cdiv(out_size, Br))\n",
    "\n",
    "    DEVICE = torch.device(device)\n",
    "    props = torch.cuda.get_device_properties(DEVICE)\n",
    "    if props.major ==8:\n",
    "        if props.minor == 9: #Ada\n",
    "            max_th = 24*props.multi_processor_count\n",
    "        elif props.minor == 0: #Ampere\n",
    "            max_th = 32*props.multi_processor_count\n",
    "    elif props.major==7:\n",
    "        max_th = 16*props.multi_processor_count # Turing\n",
    "    resto = gsize%max_th\n",
    "    if resto !=0:\n",
    "        wave_sze =gsize+ (max_th-resto)\n",
    "\n",
    "    w_out = torch.empty((real_shape), device=device, dtype = out_dtype \n",
    "                        if out_dtype == torch.float16 else torch.bfloat16, requires_grad=False)\n",
    "    \n",
    "    grid = lambda META: ((wave_sze,))\n",
    "    out = _your_dequantize_nf4_kernel[grid](weight, w_out,\n",
    "                                                         absmax, offset,\n",
    "                                                         absmax2, code2,\n",
    "                                                         block_size2, gsize, code, blocks, Br,\n",
    "                                                         num_warps = 16, num_stages=1, maxnreg=8192,\n",
    "                                                         )\n",
    "\n",
    "\n",
    "    return w_out if out_dtype == torch.float16 else w_out\n",
    "\n",
    "def your_dequantize_nf4(weight):\n",
    "    return _your_dequantize_nf4(weight.weight.data, weight.weight.quant_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a880996a-f7b1-4025-acbb-e0b505debc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2290114722981054"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TEST IT BELOW:\n",
    "# test_dequantize(your_dequantize_nf4)\n",
    "\n",
    "### CALCULATE SPEEDUP (hopefully 1.15x faster or more)\n",
    "test_dequantize(unsloth_dequantize) / test_dequantize(your_dequantize_nf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e52c13-0e04-4ff1-8378-232fc8ca087d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
